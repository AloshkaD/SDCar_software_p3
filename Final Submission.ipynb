{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light-Weight Convolutional Network for Transfer Learning in Self-Driving Cars "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I present my approach to teach a self-driving car how to drive using data collected from human-driving behaviour. The solution includes image processing and deep learning techniques. I've developed a new convolutional network cabale of generalizing to driving conditions in different terrains without apriori training on these roads. That was demonstrated by running the two simulators provided.  Using only three front cameras, the car is taught how to drive autonomously. This concept has been successfully demonstrated by Nvidia [1] and comma.ai[5]. \n",
    "The data sets were acquired by driving the a car in a simulator and collecting frames from the left, center, and right camera. Each frame is tagged with the location where it's stored. The steering angel as well as the car speed and brakes were also recorded. \n",
    "\n",
    "The project solution consists of two main parts: data processing and deep learning\n",
    "\n",
    "In the data processing the images are parsed and then preprocessed for image augmentation. \n",
    "The python generators in keras were used to augument the images on the fly and solving the memory limitation problem.\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from scipy import signal\n",
    "tf.python.control_flow_ops = tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPooling2D, Convolution2D, Input, Lambda, SpatialDropout2D \n",
    "from keras import initializations\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation,Lambda\n",
    "from keras.layers import Input, ELU\n",
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "threshold = 1\n",
    "#size of croped \n",
    "col = 64\n",
    "row = 64\n",
    "#size of generator batches\n",
    "batch_size = 64\n",
    "#number of epoches\n",
    "EPOCH=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Method to read image. CV2 reads images in BGR and the simulator provides images in RGB. Therefore convert to \n",
    "#RGB domain\n",
    "def read_img(img):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "#Image brigtness changing method, based on Vivek Yadav's [2] approach for changing image brightness\n",
    "def brightness_images(img):\n",
    "    post_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    post_img[:,:,2] = np.multiply(post_img[:,:,2],random_bright)\n",
    "    post_img = cv2.cvtColor(post_img,cv2.COLOR_HSV2RGB)\n",
    "    return post_img\n",
    "# My approach to adjust brightness used for experimentation \n",
    "def brightness_images_2(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v += 255\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "# Resize the image to the givin dimensions \n",
    "def resize_img(image, col, row):\n",
    "    image = cv2.resize(image, (col,row), interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "# Crop away the car hood from the orginal image  \n",
    "def crop_img(img):\n",
    "    shape = img.shape\n",
    "    img = img[0:shape[0]-20,0:shape[1]]\n",
    "    img = resize_img(img, 64, 64)\n",
    "    return img\n",
    "#flip raw and processed images aroung the center , as well as reverse the signal of the steering angel \n",
    "def modified_flip(image, steer):\n",
    "    image=cv2.flip(image,1)\n",
    "    steer=np.multiply(steer,-1)\n",
    "    return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Loading CSV data\n",
    "\n",
    "csv_path = 'driving_log.csv'\n",
    "raw_data = pd.read_csv(csv_path,index_col = False)\n",
    "raw_data.columns = ['center', 'left', 'right', 'steer', 'throttle', 'brake', 'speed']\n",
    "raw_steer = np.array(raw_data.steer,dtype=np.float32)\n",
    "raw_data['steering'] = pd.Series(raw_steer, index=raw_data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine all filters in this method and call it from the keras generator. There are two main methods, one for\n",
    "#training and the other for validation.\n",
    "\n",
    "def all_filters_train(generator_csv):\n",
    "    #Use the left, center and right images randomly from datasets. \n",
    "    #The chance of each image to be picked was determined empirically  \n",
    "    rand_value= np.random.randint(8)\n",
    "    if (rand_value == 0) or (rand_value == 1) or (rand_value == 2) or (rand_value == 3):\n",
    "        img_data = generator_csv['center'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        steer_ang = generator_csv['steering'][0] \n",
    "    #in 1/4 of cases flip the image and change the steering angle\n",
    "    if (rand_value == 4):\n",
    "        img_data = generator_csv['center'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        image = cv2.flip(image,1)\n",
    "        steer_ang = generator_csv['steering'][0] * -1 \n",
    "    if (rand_value == 5):\n",
    "        img_data = generator_csv['left'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        steer_ang = generator_csv['steering'][0] + 0.15\n",
    "    if (rand_value == 6):\n",
    "        img_data = generator_csv['right'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        steer_ang = generator_csv['steering'][0] - 0.15 \n",
    "    if (rand_value == 7):\n",
    "        img_data = generator_csv['left'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        image = cv2.flip(image,1)\n",
    "        steer_ang = (generator_csv['steering'][0] * -1) - 0.15 \n",
    "    if (rand_value == 8):\n",
    "        img_data = generator_csv['right'][0].strip()\n",
    "        image = cv2.imread(img_data)\n",
    "        image = cv2.flip(image,1)\n",
    "        steer_ang = (generator_csv['steering'][0] * -1) + 0.15 \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = brightness_images(image)\n",
    "    image = crop_img(image)\n",
    "    image = np.array(image)\n",
    "    return image,steer_ang\n",
    "# Validation filters method combined  \n",
    "def all_filters_validate(generator_csv):\n",
    "    img_data = generator_csv['center'][0].strip()\n",
    "    image = cv2.imread(img_data)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = crop_img(image)\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "# Save model for Keras and generators are based on Vevik Yadav's and Save and Load Your Keras Deep Learning Models\n",
    "#by Jason Brownlee  \n",
    "\n",
    "def generate_train_batch(data,batch_size):\n",
    "    batch_images = np.zeros((batch_size, col, row, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            process_line = np.random.randint(len(data))\n",
    "            generator_csv= data.iloc[[process_line]].reset_index()\n",
    "            x,y = all_filters_train(generator_csv)\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering\n",
    "\n",
    "def generate_validation_patch(data):\n",
    "    while 1:\n",
    "        for process_line in range(len(data)):\n",
    "            generator_csv = data.iloc[[process_line]].reset_index()\n",
    "            x = all_filters_validate(data)\n",
    "            x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "            y = generator_csv['steering'][0]\n",
    "            y = np.array([[y]])\n",
    "            yield x, y\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deep learning model\n",
    "\n",
    "def my_final_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (col, row, 3)\n",
    "    model = Sequential()\n",
    "    #Normalize the images with keras\n",
    "    model.add(Lambda(lambda x: x/255.-0.5,input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Convolution2D(16, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Convolution2D(24, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Convolution2D(36, 3, 3, border_mode='valid', activation='relu'))\n",
    "     \n",
    "    model.add(Convolution2D(48, 2, 2, border_mode='valid', activation='relu'))\n",
    "    model.add(Convolution2D(64, 2, 2, border_mode='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(265))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, name='output'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_3 (Lambda)                (None, 64, 64, 3)     0           lambda_input_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 32, 32, 3)     0           lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 30, 30, 16)    448         maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 15, 15, 16)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 13, 13, 24)    3480        maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 6, 6, 24)      0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 4, 4, 36)      7812        maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 3, 48)      6960        convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 2, 2, 64)      12352       convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 256)           0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           131584      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 512)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 512)           0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 265)           135945      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 265)           0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 265)           0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             266         activation_6[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 298,847\n",
      "Trainable params: 298,847\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9e667df96dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     history = model.fit_generator(train_generator,\n\u001b[1;32m     21\u001b[0m             \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50304\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         nb_val_samples=val_size) \n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mfileModelJSON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfileWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1507\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1509\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model definition \n",
    "model = my_final_model()\n",
    "#Use adam with 0.0001 learning rate\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,loss='mse')\n",
    "\n",
    "#The code is based on Keras's generator implementation, Comma.ai, and Vevik Yadev's \n",
    "### threshold reduced over training to include more small angles\n",
    "valid_generator =generate_validation_patch(raw_data)\n",
    "val_size = len(raw_data)\n",
    "threshold = 1\n",
    "highest_score = 0\n",
    "best_value = 1000\n",
    "for i in range(EPOCH):\n",
    "    train_generator = generate_train_batch(raw_data,batch_size)\n",
    "    nb_vals = np.round(len(raw_data)/val_size)-1\n",
    "    #fit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=None, \n",
    "    #validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, \n",
    "    #initial_epoch=0)\n",
    "    history = model.fit_generator(train_generator,\n",
    "            samples_per_epoch=50304, nb_epoch=1,validation_data=valid_generator,\n",
    "                        nb_val_samples=val_size) \n",
    "    fileModelJSON = 'model_' + str(i) + '.json'\n",
    "    fileWeights = 'model_' + str(i) + '.h5'\n",
    "    \n",
    "    save_model(fileModelJSON,fileWeights)\n",
    "    \n",
    "    loss_value = history.history['val_loss'][0]\n",
    "    if loss_value < best_value:\n",
    "        highest_score = i \n",
    "        best_value= loss_value\n",
    "        fileModelJSON = 'model_best.json'\n",
    "        fileWeights = 'model_best.h5'\n",
    "        save_model(fileModelJSON,fileWeights)\n",
    "    \n",
    "    threshold = 1/(i+1)\n",
    "print('Best model found at iteration # ' + str(highest_score))\n",
    "print('Best Validation score : ' + str(np.round(best_value,4)))\n",
    "\n",
    "### \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### References and Acknowledgment\n",
    "\n",
    "Paul Heraty's  great insights and recommendations about behavioral cloning [3] where very helpful in deciding what strategy is most efficient in solving this p. Also, comma.ai's[4]and[5] model was a good starting point.\n",
    "Kunfeng Chen's blog was also helpfull in determining what combination of loss/accuracy make the best model.\n",
    "\n",
    "[1]http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "[2]https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.dcwx90st3\n",
    "[3]https://carnd-forums.udacity.com/questions/26214464/behavioral-cloning-cheatsheet\n",
    "[4]https://arxiv.org/pdf/1608.01230v1.pdf\n",
    "[5]https://github.com/commaai/research/blob/master/train_steering_model.py\n",
    "[6]https://medium.com/@KunfengChen/training-and-validation-loss-mystery-in-behavioral-cloning-for-cnn-from-udacity-sdc-project-3-dfe3eda596ba#.2mnauogtg"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
